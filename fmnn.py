# -*- coding: utf-8 -*-
"""Final_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P1g-YicAUrfoU2W4AGKeh2rch10AF42q
"""

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import random
import numpy as np

# Define a transform to convert the images to tensors and normalize them
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert image to tensor
    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]
])

# Load the Fashion-MNIST dataset
train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)

# Class labels in Fashion-MNIST
class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Dictionary to store indices for each class
class_indices = {i: [] for i in range(10)}

# Group indices by class
for idx, (_, label) in enumerate(train_dataset):
    class_indices[label].append(idx)

# Select one random sample for each class
sample_images = {}
for label in range(10):
    # Randomly select an index for this class
    random_idx = random.choice(class_indices[label])
    img, _ = train_dataset[random_idx]
    sample_images[label] = img

# Plot the selected images
fig, axes = plt.subplots(1, 10, figsize=(20, 4))
for i, (label, img) in enumerate(sample_images.items()):
    axes[i].imshow(img.squeeze(), cmap='gray')
    axes[i].set_title(class_labels[label])
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Check dataset sizes
print(f"Training Set Size: {len(train_dataset)}")
print(f"Test Set Size: {len(test_dataset)}")

from torch.utils.data import DataLoader

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Function to flatten images before feeding them into the model
def preprocess_batch(batch):
    images, labels = batch
    images = images.view(images.shape[0], -1)  # Flatten to (batch_size, 784)
    assert images.shape == (64, 784), f"Unexpected images shape: {images.shape}"
    assert labels.shape == (64,), f"Unexpected labels shape: {labels.shape}"
    return images, labels

# Verify the preprocessing
for batch in train_loader:
    images, labels = preprocess_batch(batch)
    print(f"Processed Batch Shape: {images.shape}, Labels Shape: {labels.shape}")
    break

import torch

class SimpleNN:
    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):
        self.layers = []
        self.learning_rate = learning_rate  # Learning rate for SGD

        # Creating weight & bias tensors for each layer
        layer_sizes = [input_size] + hidden_sizes + [output_size]
        for i in range(len(layer_sizes) - 1):
            weights = torch.randn(layer_sizes[i + 1], layer_sizes[i]) * 0.01
            bias = torch.zeros(layer_sizes[i + 1], 1)
            self.layers.append((weights, bias))

    def relu(self, x):
        return torch.max(torch.tensor(0.0), x)

    def relu_derivative(self, x):
        return (x > 0).float()

    def softmax(self, x):
        exp_x = torch.exp(x - torch.max(x, dim=0, keepdim=True)[0])  # Prevent overflow
        return exp_x / torch.sum(exp_x, dim=0, keepdim=True)

    def cross_entropy_loss(self, predictions, labels):
        batch_size = labels.shape[1]
        one_hot_labels = torch.zeros_like(predictions)
        one_hot_labels.scatter_(0, labels, 1)  # Convert labels to one-hot encoding
        loss = -torch.sum(one_hot_labels * torch.log(predictions + 1e-9)) / batch_size  # Avoid log(0)
        return loss

    def model(self, xb):
        activations = [xb]  # Store activations for backpropagation
        for i, (weights, bias) in enumerate(self.layers):
            xb = torch.matmul(weights, xb) + bias  # Linear transformation
            if i < len(self.layers) - 1:
                xb = self.relu(xb)  # Apply ReLU for hidden layers
            activations.append(xb)
        return self.softmax(xb), activations  # Softmax for output layer

    def backward(self, xb, yb, activations):
        batch_size = yb.shape[1]
        one_hot_labels = torch.zeros_like(activations[-1])
        one_hot_labels.scatter_(0, yb, 1)

        # Compute gradient of loss w.r.t. output
        grad = activations[-1] - one_hot_labels

        # Backpropagate through layers
        for i in range(len(self.layers) - 1, -1, -1):
            weights, bias = self.layers[i]

            dW = torch.matmul(grad, activations[i].T) / batch_size  # Gradient of weights
            dB = torch.sum(grad, dim=1, keepdim=True) / batch_size  # Gradient of bias

            if i > 0:
                grad = torch.matmul(weights.T, grad) * self.relu_derivative(activations[i])  # Backpropagate

            # Update parameters using SGD
            self.layers[i] = (weights - self.learning_rate * dW, bias - self.learning_rate * dB)

    def train(self, train_loader, test_loader, epochs=5):
        for epoch in range(epochs):
            correct_train = 0
            total_train = 0
            total_loss = 0

            for images, labels in train_loader:
                # Flatten images
                images = images.view(images.shape[0], -1).T
                labels = labels.view(1, -1)

                # Forward pass
                outputs, activations = self.model(images)

                # Compute loss
                loss = self.cross_entropy_loss(outputs, labels)
                total_loss += loss.item()

                # Compute accuracy
                predictions = torch.argmax(outputs, dim=0)
                correct_train += (predictions == labels).sum().item()
                total_train += labels.shape[1]

                # Backward pass
                self.backward(images, labels, activations)

            # Compute train accuracy
            train_accuracy = correct_train / total_train * 100

            # Compute test accuracy
            correct_test = 0
            total_test = 0

            for images, labels in test_loader:
                images = images.view(images.shape[0], -1).T
                labels = labels.view(1, -1)

                outputs, _ = self.model(images)
                predictions = torch.argmax(outputs, dim=0)
                correct_test += (predictions == labels).sum().item()
                total_test += labels.shape[1]

            test_accuracy = correct_test / total_test * 100

            # Print results
            print(f"Epoch {epoch + 1}/{epochs}: Loss = {total_loss:.4f}, Train Acc = {train_accuracy:.2f}%, Test Acc = {test_accuracy:.2f}%")

input_size = 784  # 28x28 flattened image
hidden_sizes = [128, 64]  # Example hidden layers
output_size = 10  # 10 classes for Fashion-MNIST

# Create model
model = SimpleNN(input_size, hidden_sizes, output_size, learning_rate=0.01)

# Train model
model.train(train_loader, test_loader, epochs=20)

import torch
import matplotlib.pyplot as plt
import random
import numpy as np

def test_and_visualize_model(model, test_loader, class_labels):
    # Calculate overall test accuracy
    correct = 0
    total = 0
    all_images = []
    all_labels = []
    all_predictions = []

    # Process all test data
    with torch.no_grad():  # No need to track gradients for testing
        for images, labels in test_loader:
            # Store original images for visualization
            all_images.extend(images.numpy())
            all_labels.extend(labels.numpy())

            # Preprocess images for model
            images = images.view(images.shape[0], -1).T
            labels = labels.view(1, -1)

            # Get predictions
            outputs, _ = model.model(images)
            predictions = torch.argmax(outputs, dim=0)
            all_predictions.extend(predictions.numpy())

            # Calculate accuracy
            correct += (predictions == labels).sum().item()
            total += labels.shape[1]

    # Calculate final accuracy
    test_accuracy = (correct / total) * 100
    print(f"\nFinal Test Accuracy: {test_accuracy:.2f}%")

    # Select 9 random indices for visualization
    num_samples = len(all_images)
    indices = random.sample(range(num_samples), 9)

    # Create a 3x3 grid of subplots
    fig, axes = plt.subplots(3, 3, figsize=(15, 15))
    for idx, ax in zip(indices, axes.ravel()):
        # Get image and labels
        image = all_images[idx].squeeze()
        true_label = all_labels[idx]
        pred_label = all_predictions[idx]

        # Display image
        ax.imshow(image, cmap='gray')

        # Set title with true and predicted labels
        title = f'True: {class_labels[true_label]}\nPred: {class_labels[pred_label]}'
        ax.set_title(title, color='green' if true_label == pred_label else 'red')
        ax.axis('off')

    plt.tight_layout()
    plt.show()

# Test the model and visualize results
test_and_visualize_model(model, test_loader, class_labels)